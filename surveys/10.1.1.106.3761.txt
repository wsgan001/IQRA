10.1.1.106.3761	2005	Multimodal human computer interaction: A survey
R1	10.1.1.117.1491	Human-Computer Interaction
R1	10.1.1.1.9283	Designing, Playing, and Performing with a Vision-Based Mouth Interface
R1	10.1.1.31.3660	The Open Agent Architecture: A Framework for Building Distributed Software Systems
R1	10.1.1.353.4090	Visual interpretation of hand gestures for human-computer interaction: A review
R1	10.1.1.27.208	Ten Myths of Multimodal Interaction
R1	10.1.1.131.2072	The Visual Analysis of Human Movement: A Survey
R1	10.1.1.29.8715	User Modeling in Adaptive Interfaces
R1	10.1.1.46.3359	Face Recognition Using An Embedded HMM
R1	10.1.1.1.4116	Semi-supervised Learning of Classifiers: Theory, Algorithms and Their Application to Human-Computer Interaction
R1	10.1.1.25.5398	Automatic Analysis of Facial Expressions: The State of the Art
R1	10.1.1.16.1273	Facial Expression Recognition from Video Sequences: Temporal and Static Modelling
R1	10.1.1.21.513	The Recognition of Human Movement Using Temporal Templates
R1	10.1.1.108.203	A Survey of Computer Vision-Based Human Motion Capture
R1	10.1.1.39.4520	Mutual Disambiguation of Recognition Errors in a Multimodal Architecture
R1	10.1.1.27.7641	Tracking and Recognizing Rigid and Non-Rigid Facial Motions using Local Parametric Models of Image Motion
R1	10.1.1.40.359	Coding, Analysis, Interpretation, and Recognition of Facial Expressions
R1	10.1.1.13.9046	The Logic of Typed Feature Structures
R1	10.1.1.1.7446	Automatic Analysis of Multimodal Group Actions in Meetings
R1	10.1.1.2.3987	Using Eye Region Biometrics to Reveal Affective and Cognitive States
R1	10.1.1.29.4014	Optical Tracking for Music and Dance Performance
R1	10.1.1.129.4143	Bricks: Laying the foundations for graspable user interfaces
R1	10.1.1.37.5470	Multimodal Interfaces That Process What Comes Naturally
R1	10.1.1.22.2072	LAFTER: A Real-time Face and Lips Tracker with Facial Expression Recognition
R1	10.1.1.17.9536	A Unified Approach To Coding and Interpreting Face Images
R1	10.1.1.24.1931	Multimodality In Language And Speech Systems - From Theory To Design Support Tool
R1	10.1.1.7.4339	Foundations of Multimodal Representations - A Taxonomy of Representational Modalities
R1	10.1.1.22.7948	Designing the User Interface for Multimodal Speech and Pen-based Gesture Applications: State-of-the-Art Systems and Future Research Directions
R1	10.1.1.10.7352	A Multimodal Learning Interface for Grounding Spoken Language in Sensory Perceptions
R1	10.1.1.109.6470	Information fusion in biometrics
R1	10.1.1.408.8589	Real-time eye, gaze, and face pose tracking for monitoring driver vigilance
R1	10.1.1.133.8461	The use of eye movements in human-computer interaction techniques: What you look at is what you get
R1	10.1.1.115.1376	Vision for a Smart Kiosk
R1	10.1.1.33.1946	Automatic Recognition of Facial Expressions Using Hidden Markov Models and Estimation of Expression Intensity
R1	10.1.1.25.4322	Evaluation of Eye Gaze Interaction
R1	10.1.1.18.150	A Design Space for Multimodal Systems: Concurrent Processing and Data Fusion
R1	10.1.1.3.2728	Toward an Affect-Sensitive Multimodal Human-Computer Interaction
R1	10.1.1.42.4572	Human Hand Modeling, Analysis and Animation in the Context of HCI
R1	10.1.1.93.1814	Real-time gesture recognition by learning and selective control of visual interest points
R1	10.1.1.51.2892	Recognizing Multiple Persons' Facial Expressions Using HMM Based on Automatic Extraction of Significant Frames from Image Sequences
R1	10.1.1.117.16	Direct Manipulation for Comprehensible, Predictable and Controllable User Interfaces
R1	10.1.1.13.4671	Speech-Gesture Driven Multimodal Interfaces for Crisis Management
R1	10.1.1.134.7190	Recent Developments in Human Motion Analysis
R1	10.1.1.15.3658	QuickSet: Multimodal Interaction for Distributed Applications
R1	10.1.1.115.2861	A survey on visual surveillance of object motion and behaviors
R1	10.1.1.6.6700	A Framework for Rapid Development of Multimodal Interfaces
R1	10.1.1.106.3761	Multimodal human computer interaction: A survey
R1	10.1.1.64.9237	A living laboratory for the design and evaluation of ubiquitous computing technologies
R1	10.1.1.140.2705	Communication via eye blinks and eyebrow raises: Video-based human-computer interfaces
R1	10.1.1.231.8413	The Production and Recognition of Emotions in Speech: Features and Algorithms
R1	10.1.1.323.6961	Augmenting and Sharing Memory with eyeBlog
R1	10.1.1.3.3025	Tracking Articulated Body by Dynamic Markov Network
R1	10.1.1.2.5233	"Eigenlips" for Robust Speech Recognition
R1	10.1.1.13.3950	A Survey of Research on Context-Aware Homes
R1	10.1.1.126.4163	Multimodal Detection of Human Interaction Events in a Nursing Home Environment
R1	10.1.1.115.6508	Conversing with the user based on eye-gaze patterns
R1	10.1.1.9.4306	Ontology and Taxonomy Collaborated Framework for Meeting Classification
R1	10.1.1.20.187	Learning Body Pose via Specialized Maps
R1	10.1.1.105.2158	Tactile Interfaces: a State-of-the-Art Survey
R1	10.1.1.226.1128	Making systems sensitive to the userâ€™s time and working memory constraints
R1	10.1.1.16.9388	A Robust Algorithm for Reading Detection
R1	10.1.1.4.842	Determining Driver Visual Attention with One Camera
R1	10.1.1.11.3191	Integrating Perceptual and Cognitive Modeling for Adaptive and Intelligent Human-Computer Interaction
R1	10.1.1.128.3441	Building the Design Studio of the Future
R1	10.1.1.15.6024	A Reference Model for Output Information in Intelligent Multimedia Presentation Systems
R1	10.1.1.125.607	Multimodal 'Eyes-Free' Interaction Techniques for Wearable Devices
R1	10.1.1.69.8882	Multimodal input fusion in humancomputer interaction on the example of the on-going nice project
R1	10.1.1.59.1930	Face and Body Gesture Recognition for a Vision-Based Multimodal Analyzer
R1	10.1.1.331.4029	Affective Meeting Video Analysis
R1	10.1.1.110.8256	Multimodal applications from mobile to kiosk
R1	10.1.1.72.1889	Meticulously detailed eye region model and its application to analysis of facial images
R1	10.1.1.16.7741	Experimental Evaluation of Vision and Speech based Multimodal Interfaces
R1	10.1.1.53.6705	An Architecture for Multimodal Information Fusion
R1	10.1.1.7.5282	The Museum Wearable: real-time sensor-driven understanding of visitors' interests for personalized visually-augmented museum experiences
R1	10.1.1.58.9641	Occupant Posture Analysis with Stereo and Thermal Infrared Video: Algorithms and Experimental Evaluation
R1	10.1.1.169.5933	PERCEPTUAL INTERFACES
R1	10.1.1.58.7901	Automatic 2D Hand Tracking in Video Sequences
