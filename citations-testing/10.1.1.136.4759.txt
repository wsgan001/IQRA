10.1.1.136.4759	2007	Nonparametric Bayesian Models of Lexical Acquisition
R1	10.1.1.133.4884	Maximum likelihood from incomplete data via the EM algorithm
R1	10.1.1.117.1928	Finding structure in time
R1	10.1.1.101.9086	Term-weighting approaches in automatic text retrieval
R1	10.1.1.110.4050	Latent dirichlet allocation
R1	10.1.1.27.7690	Modern Information Retrieval
R1	10.1.1.14.9706	Building a Large Annotated Corpus of English: The Penn Treebank
R1	10.1.1.19.9180	A Maximum-Entropy-Inspired Parser
R1	10.1.1.13.8919	The Mathematics of Statistical Machine Translation: Parameter Estimation
R1	10.1.1.36.9055	Probabilistic Inference Using Markov Chain Monte Carlo Methods
R1	10.1.1.16.2929	The Infinite Hidden Markov Model
R1	10.1.1.14.4345	A Maximum Entropy Model for Part-Of-Speech Tagging
R1	10.1.1.33.1129	Distributional Regularity and Phonotactic Constraints are Useful for Segmentation
R1	10.1.1.13.8615	A Stochastic Finite-State Word-Segmentation Algorithm For Chinese
R1	10.1.1.81.249	Optimality Theory: Constraint interaction in Generative Grammar
R1	10.1.1.110.383	On Sequential Monte Carlo Sampling Methods for Bayesian Filtering
R1	10.1.1.33.2557	A View Of The Em Algorithm That Justifies Incremental, Sparse, And Other Variants
R1	10.1.1.131.5458	An Empirical Study of Smoothing Techniques for Language Modeling
R1	10.1.1.27.9455	Two-Level Morphology with Composition
R1	10.1.1.43.5829	Functional Phonology -- Formalizing the interactions between articulatory and perceptual drives
R1	10.1.1.150.2795	Empirical tests of the Gradual Learning Algorithm
R1	10.1.1.371.2042	A hierarchical dirichlet language model
R1	10.1.1.5.8981	On Language and Connectionism: Analysis of a Parallel Distributed Processing Model of Language Acquisition
R1	10.1.1.40.3940	Gradual Constraint-Ranking Learning Algorithm Predicts Acquisition Order
R1	10.1.1.14.6472	Tagging English Text with a Probabilistic Model
R1	10.1.1.10.9763	Unsupervised Discovery of Morphemes
R1	10.1.1.133.2731	Shortlist: a connectionist model of continuous speech recognition
R1	10.1.1.113.7572	Hierarchical topic models and the nested Chinese restaurant process
R1	10.1.1.15.88	Improving Stemming for Arabic Information Retrieval: Light Stemming and Co-occurrence Analysis
R1	10.1.1.130.3689	Learnability in Optimality Theory
R1	10.1.1.150.3484	Minimally supervised morphological analysis by multimodal alignment
R1	10.1.1.128.4103	Mostly-Unsupervised Statistical Segmentation of Japanese: Applications to Kanji
R1	10.1.1.10.9194	Probabilistic Phonotactics and Neighborhood Activation in Spoken Word Recognition
R1	10.1.1.140.5348	An efficient, probabilistically sound algorithm for segmentation and word discovery
R1	10.1.1.18.5623	The Unsupervised Acquisition of a Lexicon from Continuous Speech
R1	10.1.1.51.1747	Bayesian Density Estimation and Inference Using Mixtures
R1	10.1.1.138.5390	Learning at a distance I. Statistical learning of non-adjacent dependencies
R1	10.1.1.100.9159	Accessor variety criteria for chinese word extraction
R1	10.1.1.38.599	Discovering Chinese Words from Unsegmented Text
R1	10.1.1.122.8637	Hierarchical Dirichlet processes
R1	10.1.1.30.764	The two-parameter Poisson-Dirichlet distribution derived from a stable subordinator.
R1	10.1.1.74.6624	Clustering documents with an exponential-family approximation of the dirichlet compound multinomial distribution
R1	10.1.1.324.5134	Modeling word burstiness using the Dirichlet distribution
R1	10.1.1.33.1219	Tagging Inflective Languages: Prediction of Morphological Categories for a Rich, Structured Tagset
R1	10.1.1.14.4154	Statistical Morphological Disambiguation for Agglutinative Languages
R1	10.1.1.12.2061	The Role of Exposure to Isolated Words in Early Vocabulary Development
R1	10.1.1.129.7005	Interpolating between types and tokens by estimating power-law generators
R1	10.1.1.65.2033	Language Model Based Arabic Word Segmentation
R1	10.1.1.28.6642	An Algorithm for Segmenting Categorical Time Series into Meaningful Episodes
R1	10.1.1.128.9998	Word Learning as Bayesian Inference
R1	10.1.1.49.4573	Integrating Multiple Cues in Word Segmentation: A Connectionist Model using Hints
R1	10.1.1.408.8519	Determinants of wordlikeness: Phonotactics or lexical neighborhoods
R1	10.1.1.75.5520	Generalized weighted Chinese restaurant processes for species sampling mixture models
R1	10.1.1.149.9765	Knowledge-free induction of inflectional morphologies
R1	10.1.1.45.7313	The power of statistical learning: No need for algebraic rules
R1	10.1.1.18.6769	Modeling English Past Tense Intuitions with Minimal Generalization
R1	10.1.1.19.5103	A Statistical Model for Word Discovery in Transcribed Speech
R1	10.1.1.23.5941	Are Non-Semantic Morphological Effects Incompatible With a Distributed Connectionist Approach to Lexical Processing?
R1	10.1.1.132.5554	Stochastic phonology
R1	10.1.1.33.4704	Learnability in Optimality Theory (long version)
R1	10.1.1.43.3128	Prosodic Constraints and the Learner's Environment: a Corpus Study
R1	10.1.1.47.8768	The Iterative Learning of Phonological Constraints
R1	10.1.1.22.2075	The Emergence of Words
R1	10.1.1.184.2744	A non-parametric Bayesian approach to spike sorting
R1	10.1.1.113.938	Induction of a simple morphology for highly-inflecting languages
R1	10.1.1.132.4004	Unsupervised Induction of Natural Language Morphology Inflection Classes
R1	10.1.1.135.1419	Goldâ€™s theorem and cognitive science
R1	10.1.1.304.8632	Modeling individual differences using Dirichlet processes
R1	10.1.1.126.9662	Priors in Bayesian Learning of Phonological Rules
